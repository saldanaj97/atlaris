name: CI - PR (trunk)

on:
  pull_request:
    branches: [main]
    paths-ignore:
      - '**/*.md'
      - '**/*.yaml'
      - '**/*.yml'
      - '**/*.txt'
      - '**/*.csv'
      - '**/*.log'
      - '**/*.lock'

permissions:
  contents: read
  pull-requests: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    outputs:
      code: ${{ steps.filter.outputs.code }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - uses: dorny/paths-filter@v3
        id: filter
        with:
          filters: |
            code:
              - 'src/**'
              - 'tests/**'
              - 'vitest.config.ts'
              - 'tsconfig.json'
              - 'package.json'
              - 'pnpm-lock.yaml'
              - 'drizzle.config.ts'

  lint:
    name: Lint
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9
      - name: Setup pnpm store cache
        uses: actions/cache@v4
        with:
          path: ~/.local/share/pnpm/store
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'
          cache-dependency-path: pnpm-lock.yaml
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
      - name: Run ESLint
        run: pnpm lint

  type-check:
    name: Type Check
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9
      - name: Setup pnpm store cache
        uses: actions/cache@v4
        with:
          path: ~/.local/share/pnpm/store
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'
          cache-dependency-path: pnpm-lock.yaml
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
      - name: Run TypeScript type check
        run: pnpm type-check

  code-duplication:
    name: Code Duplication Check
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9
      - name: Setup pnpm store cache
        uses: actions/cache@v4
        with:
          path: ~/.local/share/pnpm/store
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'
          cache-dependency-path: pnpm-lock.yaml
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
      - name: Run duplication check
        run: pnpm exec jscpd --exitCode 0
      - name: Generate duplication report
        if: always()
        run: |
          echo "## ðŸ” Code Duplication Check" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f jscpd-report/jscpd-report.json ]; then
            DUPLICATION=$(jq -r '.total.duplicatedLines // 0' jscpd-report/jscpd-report.json 2>/dev/null || echo "0")
            TOTAL=$(jq -r '.total.lines // 0' jscpd-report/jscpd-report.json 2>/dev/null || echo "0")
            if [ "$TOTAL" -gt 0 ]; then
              PERCENTAGE=$(awk "BEGIN {printf \"%.2f\", ($DUPLICATION/$TOTAL)*100}")
            else
              PERCENTAGE="0.00"
            fi
            echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Duplicated Lines | $DUPLICATION |" >> $GITHUB_STEP_SUMMARY
            echo "| Total Lines | $TOTAL |" >> $GITHUB_STEP_SUMMARY
            echo "| Duplication % | $PERCENTAGE% |" >> $GITHUB_STEP_SUMMARY
            echo "| Threshold | 5% |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            if (( $(echo "$PERCENTAGE > 5" | bc -l) )); then
              echo "âš ï¸ **Duplication exceeds 5% threshold**" >> $GITHUB_STEP_SUMMARY
            else
              echo "âœ… **Duplication within acceptable limits**" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "âœ… No duplication detected" >> $GITHUB_STEP_SUMMARY
          fi

  code-complexity:
    name: Code Complexity Check
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9
      - name: Setup pnpm store cache
        uses: actions/cache@v4
        with:
          path: ~/.local/share/pnpm/store
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'
          cache-dependency-path: pnpm-lock.yaml
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
      - name: Check file sizes
        run: node scripts/check-file-size.js
      - name: Generate complexity report
        if: always()
        run: |
          echo "## âš™ï¸ Code Complexity Check" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### File Size Check" >> $GITHUB_STEP_SUMMARY
          if [ -f file-size-report.json ]; then
            FILES_EXCEEDING=$(jq -r '.filesExceeding // 0' file-size-report.json 2>/dev/null || echo "0")
            THRESHOLD=$(jq -r '.threshold // 500' file-size-report.json 2>/dev/null || echo "500")
            if [ "$FILES_EXCEEDING" -gt 0 ]; then
              echo "âš ï¸ **$FILES_EXCEEDING file(s) exceed $THRESHOLD LOC threshold**" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "| File | Lines | Over Threshold |" >> $GITHUB_STEP_SUMMARY
              echo "|------|-------|-----------------|" >> $GITHUB_STEP_SUMMARY
              jq -r '.files[] | "| \(.file) | \(.lines) | +\(.lines - .threshold) |"' file-size-report.json 2>/dev/null >> $GITHUB_STEP_SUMMARY
            else
              echo "âœ… **All files within $THRESHOLD LOC threshold**" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "âœ… File size check passed" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Cyclomatic Complexity" >> $GITHUB_STEP_SUMMARY
          echo "âš ï¸ Run \`pnpm lint\` locally to check complexity violations (max: 10)" >> $GITHUB_STEP_SUMMARY

  vulnerability-scan:
    name: Security Audit
    runs-on: ubuntu-latest
    timeout-minutes: 8
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9
      - name: Run dependency audit
        run: pnpm audit --audit-level=high
        continue-on-error: true

  build:
    name: Build
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9
      - name: Setup pnpm store cache
        uses: actions/cache@v4
        with:
          path: ~/.local/share/pnpm/store
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'
          cache-dependency-path: pnpm-lock.yaml
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
      - name: Restore Next.js cache
        uses: actions/cache/restore@v4
        with:
          path: .next/cache
          key: ${{ runner.os }}-next-${{ hashFiles('pnpm-lock.yaml') }}-${{ hashFiles('next.config.ts') }}
          restore-keys: |
            ${{ runner.os }}-next-${{ hashFiles('pnpm-lock.yaml') }}-
      - name: Build Next.js app
        run: pnpm build
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          NEXT_PUBLIC_SUPABASE_URL: ${{ vars.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY: ${{ vars.NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY }}
          NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY: ${{ vars.NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY }}
      - name: Save Next.js cache
        if: always()
        uses: actions/cache/save@v4
        with:
          path: .next/cache
          key: ${{ runner.os }}-next-${{ hashFiles('pnpm-lock.yaml') }}-${{ hashFiles('next.config.ts') }}

  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: [changes]
    if: needs.changes.outputs.code == 'true'
    timeout-minutes: 20
    strategy:
      fail-fast: false
      matrix:
        shard: [1, 2]
        total: [2]
    services:
      postgres:
        image: postgres:15
        ports:
          - '5432:5432'
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: postgres
        options: >-
          --health-cmd="pg_isready -U postgres -d postgres"
          --health-interval=5s
          --health-timeout=5s
          --health-retries=10
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9
      - name: Setup pnpm store cache
        uses: actions/cache@v4
        with:
          path: ~/.local/share/pnpm/store
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'
          cache-dependency-path: pnpm-lock.yaml
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
      - name: Install PostgreSQL client
        run: sudo apt-get update && sudo apt-get install -y postgresql-client
      - name: Prepare ephemeral database
        env:
          PGPASSWORD: postgres
        run: |
          # Wait for database readiness
          for i in {1..30}; do
            if pg_isready -h localhost -p 5432 -U postgres -d postgres; then break; fi
            sleep 1
          done

          DB_NAME="ci_${GITHUB_RUN_ID}_unit_${{ matrix.shard }}_${GITHUB_JOB}"
          echo "DB_NAME=${DB_NAME}" >> $GITHUB_ENV
          psql -h localhost -p 5432 -U postgres -d postgres -v ON_ERROR_STOP=1 -c "CREATE DATABASE \"${DB_NAME}\";"

          # Defensive bootstrap (idempotent)
          psql -h localhost -p 5432 -U postgres -d "${DB_NAME}" -v ON_ERROR_STOP=1 <<'SQL'
          CREATE EXTENSION IF NOT EXISTS pgcrypto;
          DO $$ BEGIN CREATE ROLE anon NOLOGIN; EXCEPTION WHEN duplicate_object THEN NULL; END $$;
          DO $$ BEGIN CREATE ROLE authenticated NOLOGIN; EXCEPTION WHEN duplicate_object THEN NULL; END $$;
          DO $$ BEGIN CREATE ROLE service_role NOINHERIT NOLOGIN; EXCEPTION WHEN duplicate_object THEN NULL; END $$;
          CREATE SCHEMA IF NOT EXISTS auth;
          CREATE OR REPLACE FUNCTION auth.jwt() RETURNS jsonb
          LANGUAGE sql
          AS $$ SELECT COALESCE(current_setting('request.jwt.claims', true)::jsonb, '{}'::jsonb) $$;
          SQL

          echo "DATABASE_URL=postgresql://postgres:postgres@localhost:5432/${DB_NAME}" >> $GITHUB_ENV
      - name: Apply schema with Drizzle
        env:
          DATABASE_URL: ${{ env.DATABASE_URL }}
        run: pnpm db:push
      - name: Restore Vitest cache
        uses: actions/cache/restore@v4
        id: restore-vitest-cache
        with:
          path: |
            node_modules/.vite
            node_modules/.vitest
          key: ${{ runner.os }}-vitest-${{ hashFiles('pnpm-lock.yaml') }}-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-vitest-${{ hashFiles('pnpm-lock.yaml') }}-
      - name: Run unit tests
        id: test
        env:
          SKIP_DB_TEST_SETUP: 'true'
          ALLOW_DB_TRUNCATE: 'true'
          NODE_ENV: 'test'
          DATABASE_URL: ${{ env.DATABASE_URL }}
          STRIPE_SECRET_KEY: ${{ secrets.STRIPE_SECRET_KEY }}
          BASE_REF: ${{ github.base_ref }}
          SHARD: ${{ matrix.shard }}
          TOTAL: ${{ matrix.total }}
        shell: bash
        run: |
          echo "Base ref: ${BASE_REF}"
          CHANGED_FILES=""
          if [ -n "${BASE_REF}" ]; then
            git fetch --no-tags origin "${BASE_REF}" || true
            CHANGED_FILES=$(git diff --name-only "origin/${BASE_REF}"...HEAD | tr '\n' ' ' || true)
          fi

          # Filter to TS/TSX files under src/ or tests/
          FILES=$(echo "${CHANGED_FILES}" | tr ' ' '\n' | grep -E '^(src|tests)/.*\.(ts|tsx)$' || true)
          COUNT=$(echo "${FILES}" | wc -l | tr -d ' ')
          echo "Changed candidate files: ${COUNT}"

          if [ "${COUNT}" -gt 0 ] && [ "${COUNT}" -le 50 ]; then
            echo "Detected small set of changed files (${COUNT}); using related tests mode."
            if [ "${SHARD}" != "1" ]; then
              echo "Skipping related run on shard ${SHARD}/${TOTAL}; only shard 1 executes related tests."
              exit 0
            fi
            echo "Running related unit tests for changed files on shard 1/${TOTAL}..."
            pnpm vitest related --project unit --run --coverage ${FILES} || {
              echo "Related tests failed or not supported; falling back to full sharded run on this shard.";
              pnpm vitest run --project unit tests/unit \
                --shard ${SHARD}/${TOTAL} \
                --coverage \
                --coverage.thresholds.lines=0 \
                --coverage.thresholds.functions=0 \
                --coverage.thresholds.branches=0 \
                --coverage.thresholds.statements=0 \
                --reporter=default \
                --reporter=json \
                --outputFile=test-results.json;
            }
          else
            echo "No suitable changed files detected; running full sharded unit suite."
            pnpm vitest run --project unit tests/unit \
              --shard ${SHARD}/${TOTAL} \
              --coverage \
              --reporter=default \
              --reporter=json \
              --outputFile=test-results.json
          fi
      - name: Generate test summary
        if: always()
        run: |
          if [ -f test-results.json ]; then
            echo "## ðŸ§ª Unit Tests - Shard ${{ matrix.shard }}/${{ matrix.total }}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            # Extract test counts from JSON
            TOTAL=$(jq -r '.numTotalTests // 0' test-results.json 2>/dev/null || echo "0")
            PASSED=$(jq -r '.numPassedTests // 0' test-results.json 2>/dev/null || echo "0")
            FAILED=$(jq -r '.numFailedTests // 0' test-results.json 2>/dev/null || echo "0")
            SKIPPED=$(jq -r '.numPendingTests // 0' test-results.json 2>/dev/null || echo "0")

            echo "| Metric | Count |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| âœ… Passed | $PASSED |" >> $GITHUB_STEP_SUMMARY
            echo "| âŒ Failed | $FAILED |" >> $GITHUB_STEP_SUMMARY
            echo "| â­ï¸ Skipped | $SKIPPED |" >> $GITHUB_STEP_SUMMARY
            echo "| ðŸ“Š Total | $TOTAL |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            if [ "$FAILED" -gt 0 ]; then
              echo "âŒ **Tests failed in this shard**" >> $GITHUB_STEP_SUMMARY
            else
              echo "âœ… **All tests passed in this shard**" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "âš ï¸ Test results file not found for shard ${{ matrix.shard }}" >> $GITHUB_STEP_SUMMARY
          fi
      - name: Upload coverage reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-unit-${{ matrix.shard }}
          path: coverage/
          retention-days: 7
          if-no-files-found: ignore
      - name: Check coverage file exists
        id: check-coverage
        if: always()
        run: |
          if [ -f coverage/lcov.info ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "âš ï¸ coverage/lcov.info not found; skipping Codecov upload"
          fi
      - name: Upload coverage to Codecov (unit)
        if: always() && steps.check-coverage.outputs.exists == 'true'
        uses: codecov/codecov-action@v4
        with:
          files: coverage/lcov.info
          flags: unit
          verbose: true
          token: ${{ secrets.CODECOV_TOKEN }}
      - name: Save Vitest cache
        if: always()
        uses: actions/cache/save@v4
        with:
          path: |
            node_modules/.vite
            node_modules/.vitest
          key: ${{ steps.restore-vitest-cache.outputs.cache-primary-key || format('{0}-vitest-{1}-{2}', runner.os, hashFiles('pnpm-lock.yaml'), github.sha) }}
      - name: Cleanup ephemeral database
        if: always()
        env:
          PGPASSWORD: postgres
        run: |
          if [ -n "${{ env.DB_NAME }}" ]; then
            echo "Dropping ephemeral database: ${{ env.DB_NAME }}"
            psql -h localhost -p 5432 -U postgres -d postgres -c "DROP DATABASE IF EXISTS \"${{ env.DB_NAME }}\";" || true
          fi

  integration-light:
    name: Integration (related or light)
    runs-on: ubuntu-latest
    needs: [changes]
    if: needs.changes.outputs.code == 'true'
    timeout-minutes: 20
    services:
      postgres:
        image: postgres:15
        ports:
          - '5432:5432'
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: postgres
        options: >-
          --health-cmd="pg_isready -U postgres -d postgres"
          --health-interval=5s
          --health-timeout=5s
          --health-retries=10
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9
      - name: Setup pnpm store cache
        uses: actions/cache@v4
        with:
          path: ~/.local/share/pnpm/store
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'
          cache-dependency-path: pnpm-lock.yaml
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
      - name: Install PostgreSQL client
        run: sudo apt-get update && sudo apt-get install -y postgresql-client
      - name: Prepare ephemeral database
        env:
          PGPASSWORD: postgres
        run: |
          # Wait for database readiness
          for i in {1..30}; do
            if pg_isready -h localhost -p 5432 -U postgres -d postgres; then break; fi
            sleep 1
          done

          DB_NAME="ci_${GITHUB_RUN_ID}_int_light_${GITHUB_JOB}"
          echo "DB_NAME=${DB_NAME}" >> $GITHUB_ENV
          psql -h localhost -p 5432 -U postgres -d postgres -v ON_ERROR_STOP=1 -c "CREATE DATABASE \"${DB_NAME}\";"

          # Defensive bootstrap (idempotent)
          psql -h localhost -p 5432 -U postgres -d "${DB_NAME}" -v ON_ERROR_STOP=1 <<'SQL'
          CREATE EXTENSION IF NOT EXISTS pgcrypto;
          DO $$ BEGIN CREATE ROLE anon NOLOGIN; EXCEPTION WHEN duplicate_object THEN NULL; END $$;
          DO $$ BEGIN CREATE ROLE authenticated NOLOGIN; EXCEPTION WHEN duplicate_object THEN NULL; END $$;
          DO $$ BEGIN CREATE ROLE service_role NOINHERIT NOLOGIN; EXCEPTION WHEN duplicate_object THEN NULL; END $$;
          CREATE SCHEMA IF NOT EXISTS auth;
          CREATE OR REPLACE FUNCTION auth.jwt() RETURNS jsonb
          LANGUAGE sql
          AS $$ SELECT COALESCE(current_setting('request.jwt.claims', true)::jsonb, '{}'::jsonb) $$;
          SQL

          echo "DATABASE_URL=postgresql://postgres:postgres@localhost:5432/${DB_NAME}" >> $GITHUB_ENV
      - name: Apply schema with Drizzle
        env:
          DATABASE_URL: ${{ env.DATABASE_URL }}
        run: pnpm db:push
      - name: Restore Vitest cache
        uses: actions/cache/restore@v4
        id: restore-vitest-cache
        with:
          path: |
            node_modules/.vite
            node_modules/.vitest
          key: ${{ runner.os }}-vitest-${{ hashFiles('pnpm-lock.yaml') }}-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-vitest-${{ hashFiles('pnpm-lock.yaml') }}-
      - name: Run fast integration tests
        env:
          NODE_ENV: 'test'
          ALLOW_DB_TRUNCATE: 'true'
          DATABASE_URL: ${{ env.DATABASE_URL }}
          BASE_REF: ${{ github.base_ref }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          NEXT_PUBLIC_SUPABASE_URL: ${{ vars.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY: ${{ vars.NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY }}
          TEST_JWT_SECRET: ${{ secrets.TEST_JWT_SECRET }}
        shell: bash
        run: |
          echo "Base ref: ${BASE_REF}"
          CHANGED_FILES=""
          if [ -n "${BASE_REF}" ]; then
            git fetch --no-tags origin "${BASE_REF}" || true
            CHANGED_FILES=$(git diff --name-only "origin/${BASE_REF}"...HEAD | tr '\n' ' ' || true)
          fi

          FILES=$(echo "${CHANGED_FILES}" | tr ' ' '\n' | grep -E '^(src|tests)/.*\.(ts|tsx)$' || true)
          COUNT=$(echo "${FILES}" | wc -l | tr -d ' ')
          echo "Changed candidate files: ${COUNT}"

          # Global changes that should skip related integration and rely on light subset
          read -r -d '' GLOBAL_TRIGGER_PATTERN <<'EOF' || true
          ^(
            pnpm-lock\.yaml|
            drizzle(.*)\.config\.ts|
            drizzle-test\.config\.ts|
            vitest(\.integration)?\.config\.ts|
            vitest\.config\.ts|
            tsconfig\.json|
            package\.json|
            src/lib/db/(schema|enums|migrations|drizzle)\.ts
          )$
          EOF
          # Remove newlines and spaces for grep -E compatibility
          GLOBAL_TRIGGER_PATTERN_CLEAN=$(echo "${GLOBAL_TRIGGER_PATTERN}" | tr -d '\n' | sed 's/ //g')
          GLOBAL_TRIGGER=$(echo "${CHANGED_FILES}" | tr ' ' '\n' | grep -E "${GLOBAL_TRIGGER_PATTERN_CLEAN}" || true)
          if [ -n "${GLOBAL_TRIGGER}" ]; then
            echo "Detected global change impacting many tests; skipping related integration."
            COUNT=0
          fi

          if [ "${COUNT}" -gt 0 ] && [ "${COUNT}" -le 50 ]; then
            echo "Running vitest related for integration project..."
            pnpm vitest related --project integration --run --coverage \
              --reporter=default \
              --reporter=json \
              --outputFile=test-results.json \
              ${FILES}
            EXIT=$?
            if [ $EXIT -eq 0 ]; then
              echo "Related integration run completed."
              # Ensure coverage file exists before exiting
              if [ -f coverage/lcov.info ]; then
                echo "Coverage report generated successfully."
              else
                echo "âš ï¸ Warning: coverage/lcov.info not found after test run"
              fi
              exit 0
            else
              echo "Related run failed; falling back to light subset."
            fi
          else
            echo "No suitable changed files; using light subset."
          fi

          # Light subset fallback (or primary when no related)
          mapfile -t LIGHT_FILES < <(find tests/integration -type f -path '*/light/*' \( -name "*.test.ts" -o -name "*.spec.ts" -o -name "*.test.tsx" -o -name "*.spec.tsx" \))
          if [ "${#LIGHT_FILES[@]}" -eq 0 ]; then
            echo "No light integration tests found; skipping."
            exit 0
          fi
          pnpm vitest run "${LIGHT_FILES[@]}" \
            --coverage \
            --reporter=default \
            --reporter=json \
            --outputFile=test-results.json
      - name: Generate test summary
        if: always()
        run: |
          if [ -f test-results.json ]; then
            echo "## ðŸ”Ž Integration (PR)" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            TOTAL=$(jq -r '.numTotalTests // 0' test-results.json 2>/dev/null || echo "0")
            PASSED=$(jq -r '.numPassedTests // 0' test-results.json 2>/dev/null || echo "0")
            FAILED=$(jq -r '.numFailedTests // 0' test-results.json 2>/dev/null || echo "0")
            SKIPPED=$(jq -r '.numPendingTests // 0' test-results.json 2>/dev/null || echo "0")
            echo "| Metric | Count |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| âœ… Passed | $PASSED |" >> $GITHUB_STEP_SUMMARY
            echo "| âŒ Failed | $FAILED |" >> $GITHUB_STEP_SUMMARY
            echo "| â­ï¸ Skipped | $SKIPPED |" >> $GITHUB_STEP_SUMMARY
            echo "| ðŸ“Š Total | $TOTAL |" >> $GITHUB_STEP_SUMMARY
          else
            echo "âš ï¸ Test results file not found for light integration" >> $GITHUB_STEP_SUMMARY
          fi
      - name: Upload coverage reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-integration-light
          path: coverage/
          retention-days: 7
          if-no-files-found: ignore
      - name: Check coverage file exists
        id: check-coverage
        if: always()
        run: |
          if [ -f coverage/lcov.info ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "âš ï¸ coverage/lcov.info not found; skipping Codecov upload"
          fi
      - name: Upload coverage to Codecov (integration)
        if: always() && steps.check-coverage.outputs.exists == 'true'
        uses: codecov/codecov-action@v4
        with:
          files: coverage/lcov.info
          flags: integration
          verbose: true
          token: ${{ secrets.CODECOV_TOKEN }}
      - name: Save Vitest cache
        if: always()
        uses: actions/cache/save@v4
        with:
          path: |
            node_modules/.vite
            node_modules/.vitest
          key: ${{ steps.restore-vitest-cache.outputs.cache-primary-key || format('{0}-vitest-{1}-{2}', runner.os, hashFiles('pnpm-lock.yaml'), github.sha) }}
      - name: Cleanup ephemeral database
        if: always()
        env:
          PGPASSWORD: postgres
        run: |
          if [ -n "${{ env.DB_NAME }}" ]; then
            echo "Dropping ephemeral database: ${{ env.DB_NAME }}"
            psql -h localhost -p 5432 -U postgres -d postgres -c "DROP DATABASE IF EXISTS \"${{ env.DB_NAME }}\";" || true
          fi

  all-checks-pr:
    name: All Checks Passed (PR)
    needs: [changes, lint, type-check, vulnerability-scan, build, unit-tests, integration-light, code-duplication, code-complexity]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Check all required jobs succeeded
        run: |
          # Populate results using GitHub Actions expressions at render time
          declare -A results=(
            [changes]="${{ needs.changes.result }}"
            [lint]="${{ needs.lint.result }}"
            [type-check]="${{ needs['type-check'].result }}"
            [vulnerability-scan]="${{ needs.vulnerability-scan.result }}"
            [build]="${{ needs.build.result }}"
            [unit-tests]="${{ needs['unit-tests'].result }}"
            [integration-light]="${{ needs['integration-light'].result }}"
            [code-duplication]="${{ needs['code-duplication'].result }}"
            [code-complexity]="${{ needs['code-complexity'].result }}"
          )

          failed=0
          for job in changes lint type-check vulnerability-scan build unit-tests integration-light code-duplication code-complexity; do
            result="${results[$job]}"
            echo "${job} -> ${result}"
            # Treat 'success' as pass; allow 'skipped' (e.g., when changes filter is false)
            if [ "$result" != "success" ] && [ "$result" != "skipped" ]; then
              echo "âŒ Job '$job' did not succeed (result: $result)"
              failed=1
            fi
          done

          if [ "$failed" -ne 0 ]; then
            exit 1
          fi
      - name: All checks passed (PR)
        run: echo "âœ… All checks passed (PR)"

  auto-merge:
    name: Enable auto-merge on PR
    needs: [all-checks-pr]
    runs-on: ubuntu-latest
    # Auto-merge conditions (trunk):
    # 1. pull_request to 'main'
    # 2. PR from same repo (avoid forks)
    # 3. All PR checks passed
    if: ${{ github.event_name == 'pull_request'
          && github.event.pull_request.base.ref == 'main'
          && github.event.pull_request.head.repo.full_name == github.repository
          && needs['all-checks-pr'].result == 'success' }}
    permissions:
      contents: write
      pull-requests: write
    steps:
      - name: Enable auto-merge (size â‰¤ 300 lines)
        uses: actions/github-script@v8
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const pr = context.payload.pull_request
            if (!pr) {
              core.info('No PR context; skipping.')
              return
            }
            const size = (pr.additions || 0) + (pr.deletions || 0)
            core.info(`PR size: +${pr.additions} -${pr.deletions} = ${size}`)
            if (size > 300) {
              core.info('PR too large for auto-merge; skipping enablement.')
              return
            }
            const query = `query($owner:String!, $name:String!, $number:Int!) {
              repository(owner:$owner, name:$name) {
                pullRequest(number:$number) { id autoMergeRequest { enabledAt } }
              }
            }`
            const vars = { owner: context.repo.owner, name: context.repo.repo, number: pr.number }
            const data = await github.graphql(query, vars)
            const node = data.repository?.pullRequest
            if (!node) { core.warning('PR not found; skipping.'); return }
            if (node.autoMergeRequest) { core.info('Auto-merge already enabled.'); return }
            const mutation = `mutation($id:ID!){ enablePullRequestAutoMerge(input:{ pullRequestId:$id, mergeMethod:MERGE }) { pullRequest { number autoMergeRequest { enabledAt } } } }`
            try {
              const res = await github.graphql(mutation, { id: node.id })
              core.info(`Auto-merge enabled: ${JSON.stringify(res)}`)
            } catch (e) {
              core.warning('Enable "Allow auto-merge" in repo settings and ensure branch protection permits it. ' + e.message)
            }
