name: CI - Staging (staging env)

on:
  pull_request:
    branches: [main]
    paths-ignore:
      - '**/*.md'
      - '**/*.yaml'
      - '**/*.yml'
      - '**/*.txt'
      - '**/*.csv'
      - '**/*.log'
      - '**/*.lock'

  merge_group:
    branches: [main]

permissions:
  contents: read
  pull-requests: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    outputs:
      integration: ${{ steps.filter.outputs.integration }}
      e2e: ${{ steps.filter.outputs.e2e }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - uses: dorny/paths-filter@v3
        id: filter
        with:
          filters: |
            integration:
              - 'src/**'
              - 'tests/integration/**'
              - 'vitest.config.ts'
              - 'tsconfig.json'
              - 'package.json'
              - 'pnpm-lock.yaml'
              - 'drizzle.config.ts'
            e2e:
              - 'src/**'
              - 'public/**'
              - 'tests/e2e/**'
              - 'vitest.config.ts'
              - 'tsconfig.json'
              - 'next.config.ts'
              - 'package.json'
              - 'pnpm-lock.yaml'
              - 'drizzle.config.ts'

  e2e-tests:
    name: E2E / Smoke Tests
    if: (github.event_name == 'pull_request' || github.event_name == 'merge_group') && needs.changes.outputs.e2e == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [build-staging-env, changes]
    strategy:
      fail-fast: false
      matrix:
        shard: [1, 2, 3, 4]
        total: [4]
    services:
      postgres:
        image: postgres:15
        ports:
          - '5432:5432'
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: postgres
        options: >-
          --health-cmd="pg_isready -U postgres -d postgres"
          --health-interval=5s
          --health-timeout=5s
          --health-retries=10
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'
          cache-dependency-path: pnpm-lock.yaml
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
      - name: Install PostgreSQL client
        run: sudo apt-get update && sudo apt-get install -y postgresql-client
      - name: Prepare ephemeral database
        env:
          PGPASSWORD: postgres
        run: |
          # Wait for database readiness
          for i in {1..30}; do
            if pg_isready -h localhost -p 5432 -U postgres -d postgres; then break; fi
            sleep 1
          done

          DB_NAME="ci_${GITHUB_RUN_ID}_e2e_${{ matrix.shard }}_${GITHUB_JOB}"
          echo "DB_NAME=${DB_NAME}" >> $GITHUB_ENV
          psql -h localhost -p 5432 -U postgres -d postgres -v ON_ERROR_STOP=1 -c "CREATE DATABASE \"${DB_NAME}\";"

          # Defensive bootstrap (idempotent)
          psql -h localhost -p 5432 -U postgres -d "${DB_NAME}" -v ON_ERROR_STOP=1 <<'SQL'
          CREATE EXTENSION IF NOT EXISTS pgcrypto;
          DO $$ BEGIN CREATE ROLE anon NOLOGIN; EXCEPTION WHEN duplicate_object THEN NULL; END $$;
          DO $$ BEGIN CREATE ROLE authenticated NOLOGIN; EXCEPTION WHEN duplicate_object THEN NULL; END $$;
          DO $$ BEGIN CREATE ROLE service_role NOINHERIT NOLOGIN; EXCEPTION WHEN duplicate_object THEN NULL; END $$;
          CREATE SCHEMA IF NOT EXISTS auth;
          CREATE OR REPLACE FUNCTION auth.jwt() RETURNS jsonb
          LANGUAGE sql
          AS $$ SELECT COALESCE(current_setting('request.jwt.claims', true)::jsonb, '{}'::jsonb) $$;
          SQL

          echo "DATABASE_URL=postgresql://postgres:postgres@localhost:5432/${DB_NAME}" >> $GITHUB_ENV
      - name: Apply schema with Drizzle (staging)
        env:
          DATABASE_URL: ${{ env.DATABASE_URL }}
        run: pnpm db:push
      - name: Restore Vitest cache
        uses: actions/cache/restore@v4
        id: restore-vitest-cache
        with:
          path: |
            node_modules/.vite
            node_modules/.vitest
          key: ${{ runner.os }}-vitest-${{ hashFiles('pnpm-lock.yaml') }}-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-vitest-${{ hashFiles('pnpm-lock.yaml') }}-
      - name: Run E2E tests (Vitest shard ${{ matrix.shard }}/${{ matrix.total }})
        env:
          NODE_ENV: 'test'
          ALLOW_DB_TRUNCATE: 'true'
          DATABASE_URL: ${{ env.DATABASE_URL }}
          NEXT_PUBLIC_SUPABASE_URL: ${{ vars.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY: ${{ vars.NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          TEST_JWT_SECRET: ${{ secrets.TEST_JWT_SECRET }}
          NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY: ${{ vars.NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY }}
          CLERK_SECRET_KEY: ${{ secrets.CLERK_SECRET_KEY }}
          CLERK_ISSUER: ${{ secrets.CLERK_ISSUER }}
          STRIPE_SECRET_KEY: ${{ secrets.STRIPE_SECRET_KEY }}
          NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY: ${{ vars.NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY }}
          STRIPE_WEBHOOK_SECRET: ${{ secrets.STRIPE_WEBHOOK_SECRET }}
          STRIPE_STARTER_MONTHLY_PRICE_ID: ${{ secrets.STRIPE_STARTER_MONTHLY_PRICE_ID }}
          STRIPE_STARTER_YEARLY_PRICE_ID: ${{ secrets.STRIPE_STARTER_YEARLY_PRICE_ID }}
          AI_PROVIDER: ${{ vars.AI_PROVIDER }}
          AI_USE_MOCK: ${{ vars.AI_USE_MOCK }}
          AI_MAX_OUTPUT_TOKENS: ${{ vars.AI_MAX_OUTPUT_TOKENS }}
          AI_PRIMARY: ${{ vars.AI_PRIMARY }}
          AI_FALLBACK: ${{ vars.AI_FALLBACK }}
          AI_ENABLE_OPENROUTER: ${{ vars.AI_ENABLE_OPENROUTER }}
          MOCK_GENERATION_DELAY_MS: ${{ vars.MOCK_GENERATION_DELAY_MS }}
          MOCK_GENERATION_FAILURE_RATE: ${{ vars.MOCK_GENERATION_FAILURE_RATE }}
          GOOGLE_GENERATIVE_AI_API_KEY: ${{ secrets.GOOGLE_GENERATIVE_AI_API_KEY }}
          YOUTUBE_API_KEY: ${{ secrets.YOUTUBE_API_KEY }}
          CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
          CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
          CF_AI_GATEWAY: ${{ secrets.CF_AI_GATEWAY }}
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          OPENROUTER_SITE_URL: ${{ secrets.OPENROUTER_SITE_URL }}
          OPENROUTER_APP_NAME: ${{ secrets.OPENROUTER_APP_NAME }}
          STRIPE_PRO_MONTHLY_PRICE_ID: ${{ secrets.STRIPE_PRO_MONTHLY_PRICE_ID }}
          STRIPE_PRO_YEARLY_PRICE_ID: ${{ secrets.STRIPE_PRO_YEARLY_PRICE_ID }}
          DEV_CLERK_USER_ID: ${{ secrets.DEV_CLERK_USER_ID }}
          DEV_CLERK_USER_EMAIL: ${{ secrets.DEV_CLERK_USER_EMAIL }}
          DEV_CLERK_USER_NAME: ${{ secrets.DEV_CLERK_USER_NAME }}
        run: |
          set -e
          FILES=$(find tests/e2e -type f \( -name "*.test.ts" -o -name "*.spec.ts" -o -name "*.test.tsx" -o -name "*.spec.tsx" \) | wc -l || echo 0)
          if [ "$FILES" -eq 0 ]; then
            echo "No E2E test files found; skipping."
            exit 0
          fi
          SHARD=${{ matrix.shard }}
          TOTAL=${{ matrix.total }}
          if [ "$SHARD" -gt "$FILES" ]; then
            echo "Shard $SHARD exceeds file count $FILES; skipping this shard."
            exit 0
          fi
          if [ "$FILES" -lt "$TOTAL" ]; then
            TOTAL="$FILES"
          fi
          pnpm vitest run tests/e2e --shard "$SHARD/$TOTAL"
      - name: Save Vitest cache
        if: always()
        uses: actions/cache/save@v4
        with:
          path: |
            node_modules/.vite
            node_modules/.vitest
          key: ${{ steps.restore-vitest-cache.outputs.cache-primary-key || format('{0}-vitest-{1}-{2}', runner.os, hashFiles('pnpm-lock.yaml'), github.sha) }}

  integration-tests:
    name: Integration Tests
    if: (github.event_name == 'pull_request' || github.event_name == 'merge_group') && needs.changes.outputs.integration == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 25
    needs: [build-staging-env, changes]
    strategy:
      fail-fast: false
      matrix:
        shard: [1, 2, 3, 4]
        total: [4]
    services:
      postgres:
        image: postgres:15
        ports:
          - '5432:5432'
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: postgres
        options: >-
          --health-cmd="pg_isready -U postgres -d postgres"
          --health-interval=5s
          --health-timeout=5s
          --health-retries=10
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'
          cache-dependency-path: pnpm-lock.yaml
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
      - name: Install PostgreSQL client
        run: sudo apt-get update && sudo apt-get install -y postgresql-client
      - name: Prepare ephemeral database
        env:
          PGPASSWORD: postgres
        run: |
          # Wait for database readiness
          for i in {1..30}; do
            if pg_isready -h localhost -p 5432 -U postgres -d postgres; then break; fi
            sleep 1
          done

          DB_NAME="ci_${GITHUB_RUN_ID}_integration_${{ matrix.shard }}_${GITHUB_JOB}"
          echo "DB_NAME=${DB_NAME}" >> $GITHUB_ENV
          psql -h localhost -p 5432 -U postgres -d postgres -v ON_ERROR_STOP=1 -c "CREATE DATABASE \"${DB_NAME}\";"

          # Defensive bootstrap (idempotent)
          psql -h localhost -p 5432 -U postgres -d "${DB_NAME}" -v ON_ERROR_STOP=1 <<'SQL'
          CREATE EXTENSION IF NOT EXISTS pgcrypto;
          DO $$ BEGIN CREATE ROLE anon NOLOGIN; EXCEPTION WHEN duplicate_object THEN NULL; END $$;
          DO $$ BEGIN CREATE ROLE authenticated NOLOGIN; EXCEPTION WHEN duplicate_object THEN NULL; END $$;
          DO $$ BEGIN CREATE ROLE service_role NOINHERIT NOLOGIN; EXCEPTION WHEN duplicate_object THEN NULL; END $$;
          CREATE SCHEMA IF NOT EXISTS auth;
          CREATE OR REPLACE FUNCTION auth.jwt() RETURNS jsonb
          LANGUAGE sql
          AS $$ SELECT COALESCE(current_setting('request.jwt.claims', true)::jsonb, '{}'::jsonb) $$;
          SQL

          echo "DATABASE_URL=postgresql://postgres:postgres@localhost:5432/${DB_NAME}" >> $GITHUB_ENV
      - name: Apply schema with Drizzle
        env:
          DATABASE_URL: ${{ env.DATABASE_URL }}
        run: pnpm db:push
      - name: Restore Vitest cache
        uses: actions/cache/restore@v4
        id: restore-vitest-cache
        with:
          path: |
            node_modules/.vite
            node_modules/.vitest
          key: ${{ runner.os }}-vitest-${{ hashFiles('pnpm-lock.yaml') }}-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-vitest-${{ hashFiles('pnpm-lock.yaml') }}-
      - name: Run integration tests (shard ${{ matrix.shard }}/${{ matrix.total }})
        env:
          NODE_ENV: 'test'
          ALLOW_DB_TRUNCATE: 'true'
          DATABASE_URL: ${{ env.DATABASE_URL }}
          NEXT_PUBLIC_SUPABASE_URL: ${{ vars.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY: ${{ vars.NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          TEST_JWT_SECRET: ${{ secrets.TEST_JWT_SECRET }}
          NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY: ${{ vars.NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY }}
          CLERK_SECRET_KEY: ${{ secrets.CLERK_SECRET_KEY }}
          CLERK_ISSUER: ${{ secrets.CLERK_ISSUER }}
          STRIPE_SECRET_KEY: ${{ secrets.STRIPE_SECRET_KEY }}
          NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY: ${{ vars.NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY }}
          STRIPE_WEBHOOK_SECRET: ${{ secrets.STRIPE_WEBHOOK_SECRET }}
          STRIPE_STARTER_MONTHLY_PRICE_ID: ${{ secrets.STRIPE_STARTER_MONTHLY_PRICE_ID }}
          STRIPE_STARTER_YEARLY_PRICE_ID: ${{ secrets.STRIPE_STARTER_YEARLY_PRICE_ID }}
          AI_PROVIDER: ${{ vars.AI_PROVIDER }}
          AI_USE_MOCK: ${{ vars.AI_USE_MOCK }}
          AI_MAX_OUTPUT_TOKENS: ${{ vars.AI_MAX_OUTPUT_TOKENS }}
          AI_PRIMARY: ${{ vars.AI_PRIMARY }}
          AI_FALLBACK: ${{ vars.AI_FALLBACK }}
          AI_ENABLE_OPENROUTER: ${{ vars.AI_ENABLE_OPENROUTER }}
          MOCK_GENERATION_DELAY_MS: ${{ vars.MOCK_GENERATION_DELAY_MS }}
          MOCK_GENERATION_FAILURE_RATE: ${{ vars.MOCK_GENERATION_FAILURE_RATE }}
          GOOGLE_GENERATIVE_AI_API_KEY: ${{ secrets.GOOGLE_GENERATIVE_AI_API_KEY }}
          CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
          CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
          CF_AI_GATEWAY: ${{ secrets.CF_AI_GATEWAY }}
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          OPENROUTER_SITE_URL: ${{ secrets.OPENROUTER_SITE_URL }}
          OPENROUTER_APP_NAME: ${{ secrets.OPENROUTER_APP_NAME }}
          STRIPE_PRO_MONTHLY_PRICE_ID: ${{ secrets.STRIPE_PRO_MONTHLY_PRICE_ID }}
          STRIPE_PRO_YEARLY_PRICE_ID: ${{ secrets.STRIPE_PRO_YEARLY_PRICE_ID }}
          DEV_CLERK_USER_ID: ${{ secrets.DEV_CLERK_USER_ID }}
          DEV_CLERK_USER_EMAIL: ${{ secrets.DEV_CLERK_USER_EMAIL }}
          DEV_CLERK_USER_NAME: ${{ secrets.DEV_CLERK_USER_NAME }}
        run: |
          set -e
          FILES=$(find tests/integration -type f \( -name "*.test.ts" -o -name "*.spec.ts" -o -name "*.test.tsx" -o -name "*.spec.tsx" \) | wc -l || echo 0)
          if [ "$FILES" -eq 0 ]; then
            echo "No integration test files found; skipping."
            exit 0
          fi
          SHARD=${{ matrix.shard }}
          TOTAL=${{ matrix.total }}
          if [ "$SHARD" -gt "$FILES" ]; then
            echo "Shard $SHARD exceeds file count $FILES; skipping this shard."
            exit 0
          fi
          if [ "$FILES" -lt "$TOTAL" ]; then
            TOTAL="$FILES"
          fi
          pnpm vitest run tests/integration --shard "$SHARD/$TOTAL"
      - name: Save Vitest cache
        if: always()
        uses: actions/cache/save@v4
        with:
          path: |
            node_modules/.vite
            node_modules/.vitest
          key: ${{ steps.restore-vitest-cache.outputs.cache-primary-key || format('{0}-vitest-{1}-{2}', runner.os, hashFiles('pnpm-lock.yaml'), github.sha) }}

  build-staging-env:
    name: Build
    runs-on: ubuntu-latest
    environment: staging
    timeout-minutes: 10
    needs: [changes]
    if: needs.changes.outputs.integration == 'true' || needs.changes.outputs.e2e == 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'
          cache-dependency-path: pnpm-lock.yaml
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
      - name: Restore Next.js cache
        uses: actions/cache/restore@v4
        with:
          path: .next/cache
          key: ${{ runner.os }}-next-${{ hashFiles('pnpm-lock.yaml') }}-${{ hashFiles('next.config.ts') }}
          restore-keys: |
            ${{ runner.os }}-next-${{ hashFiles('pnpm-lock.yaml') }}-
      - name: Build Next.js app
        run: pnpm build
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          NEXT_PUBLIC_SUPABASE_URL: ${{ vars.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY: ${{ vars.NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY }}
          NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY: ${{ vars.NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY }}
      - name: Save Next.js cache
        if: always()
        uses: actions/cache/save@v4
        with:
          path: .next/cache
          key: ${{ runner.os }}-next-${{ hashFiles('pnpm-lock.yaml') }}-${{ hashFiles('next.config.ts') }}

  all-checks-staging:
    name: All Checks Passed (staging)
    needs: [integration-tests, e2e-tests, build-staging-env]
    if: always() && (github.event_name == 'pull_request' || github.event_name == 'merge_group')
    runs-on: ubuntu-latest
    steps:
      - name: Check all jobs
        run: |
          if [ "${{ contains(needs.*.result, 'failure') }}" == "true" ]; then
            echo "❌ One or more checks failed"
            exit 1
          elif [ "${{ contains(needs.*.result, 'cancelled') }}" == "true" ]; then
            echo "❌ One or more checks were cancelled"
            exit 1
          else
            echo "✅ All checks passed (staging)"
          fi

  auto-merge:
    name: Enable auto-merge on PR
    needs: [all-checks-staging, integration-tests, e2e-tests, changes]
    runs-on: ubuntu-latest
    if: >-
      github.event_name == 'pull_request' &&
      github.event.pull_request.base.ref == 'main' &&
      github.event.pull_request.head.ref == 'development' &&
      needs['all-checks-staging'].result == 'success' && (
        needs['integration-tests'].result == 'success' ||
        needs['e2e-tests'].result == 'success' ||
        (needs['integration-tests'].result == 'skipped' && needs['e2e-tests'].result == 'skipped') ||
        (needs.changes.outputs.integration != 'true' && needs.changes.outputs.e2e != 'true') ||
        contains(toJson(github.event.pull_request.labels), 'allow-auto-merge')
      )
    permissions:
      contents: write
      pull-requests: write
    steps:
      - name: Enable auto-merge via GraphQL
        uses: actions/github-script@v8
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            if (!context.payload.pull_request) {
              console.log('No PR context; skipping auto-merge enablement.')
              return
            }
            const prNumber = context.payload.pull_request.number
            const query = `query($owner:String!, $name:String!, $number:Int!) { repository(owner:$owner, name:$name) { pullRequest(number:$number) { id mergeStateStatus autoMergeRequest { enabledAt } } } }`
            const vars = { owner: context.repo.owner, name: context.repo.repo, number: prNumber }
            const prInfo = await github.graphql(query, vars)
            const pr = prInfo.repository.pullRequest
            if (!pr) {
              console.log('Pull request not found; skipping.')
              return
            }
            if (pr.autoMergeRequest) {
              console.log('Auto-merge already enabled; nothing to do.')
              return
            }
            const mutation = `mutation($prId:ID!) { enablePullRequestAutoMerge(input: { pullRequestId: $prId, mergeMethod: MERGE }) { pullRequest { number autoMergeRequest { enabledAt } } } }`
            try {
              const res = await github.graphql(mutation, { prId: pr.id })
              console.log('Auto-merge enabled:', JSON.stringify(res))
            } catch (e) {
              console.warn('Failed to enable auto-merge. Ensure repo setting "Allow auto-merge" is enabled and branch protection allows it. Error:', e.message)
            }
